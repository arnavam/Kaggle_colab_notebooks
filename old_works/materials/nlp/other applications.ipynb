{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPCHjhE1heWP0pUxF5C8XxQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"4zQsMtsphXnH"},"outputs":[],"source":["# @title elementry analysis\n","# download vader_lexicon using nltk.download()\n","from nltk.sentiment.vader import SentimentIntensityAnalyzer\n","import pandas as pd\n","import numpy as np\n","fileName = \"esteebrandsdata.csv\"\n","column = \"TextReview\"\n","Data = pd.read_csv(fileName,encoding=\"Latin-1\")\n","Data = Data.replace(np.nan,' ',regex=True)\n","sentences = list(Data[column])\n","sid = SentimentIntensityAnalyzer()\n","sentiments = []\n","for sentence in sentences:\n","    ss = sid.polarity_scores(sentence)\n","    sentiments.append(ss)"]},{"cell_type":"markdown","source":["elementy chatbot\n","--\n","---"],"metadata":{"id":"hQiqpB0TZojW"}},{"cell_type":"code","source":["import nltk\n","from nltk.chat.util import Chat, reflections\n","from sys import version_info\n","from string import punctuation\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import PorterStemmer, WordNetLemmatizer\n","\n","pairs = [\n","    [\n","        r\"How can I avail internet reservation facility through credit cards?\",\n","        ['Recently internet reservation facility has started on Indian Railways. The web site http://www.irctc.co.in is operational, wherein you can get the railway reservation done through Credit Cards.For more on Reservation through credit cards click here  Internet Reservation',]\n","    ],\n","    [\n","        r'Why are PNR and reservation availability queries not available after certain timings at night?',\n","        ['The online PNR and seat availability queries are fetched from the computerized reservation applications. These online reservation applications are shut down daily around 2330 hrs to 0030 hrs IST. Due to the dynamic changes taking place in the PNR status updation and the availability positions, these two types of queries have to be fetched from the online reservation applications, hence the non- availability of them after certain timings. The sheer size of these databases does not allow them to be copied over network lines.Please note that the web site is functional 24 hrs. a day and other queries (trains between any two stations, fare queries, etc.) are functional throughout the day.',]\n","    ],\n","    [\n","    r'How can I avail the enquiries, through SMS on mobile phones?',\n","    ['Now all the enquiries offered on the web site www.indianrail.gov.in are available on your mobile phone through SMS facility. For more information on the mobile service providers and the key words to be used on the mobile, please click here, SMS help . Please note that we are giving the backend service only for the SMS queries. For more information and help on key words and SMS facility, kindly contact the mobile service provider according to the table.',]\n","    ],\n","    [\n","    r'Why do sometimes the fonts, colors schemes and java scripts behave differently in some browser or browsers?',\n","    ['This web site is best viewed with Microsoft Internet Explorer 6.0 and above. It might not give desired results with other browsers. All the pages, color schemes and scripts have been tested for IE 6.0 and above. ',]\n","    ],\n","    [\n","    r'Where can I get the latest arrival and departure timings of trains, when they get delayed?',\n","    ['The latest arrival and departure timings of delayed trains, alongwith diverted routes etc. will be made available shortly on this web site only.',]\n","    ],\n","    [\n","    r'Where can I lodge complaint against any type of grievances in the Trains, Platforms, officials for problems on this web site and give suggestions?',\n","    ['The complaint software is presently under development. We try our best to forward your grievances to the concerned department. However please note that this is not always possible. Please note that all your complaints and suggestions for the improvement of the web site http://www.indianrail.gov.in  can be put on the Feedback & suggestions page. Please note that, in case of any problems, give the query type (hyper link), the inputs which you gave, and the exact error message generated by this web site. All this will help us in solving the problems quickly. In the absence of such inputs, we cannot solve the problems.',]\n","    ],\n","]"],"metadata":{"id":"qWiMOgVvjKId"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title preprocessing\n","def unique(list1):\n","    # intilize a null list\n","    unique_list = []\n","    # traverse for all elements\n","    for x in list1:\n","        # check if exists in unique_list or not\n","        if x not in unique_list:\n","            unique_list.append(x)\n","    return(unique_list)\n","lemmatiser = WordNetLemmatizer()\n","def preprocessing (sent) :\n","    rem_words = ['get', 'avail', 'who' , 'where', 'how' , 'what', 'why' , 'when', 'I', 'can']\n","    ##print(sent)\n","    # remove punctuation\n","    # convert to lower\n","    for p in list(punctuation):\n","        sent=sent.replace(p,'')\n","    sent=sent.lower().split()\n","    #remove stop words\n","    stop_words = set(stopwords.words('english'))\n","    sent = [i for i in sent if not i in stop_words]\n","    sent = [i for i in sent if not i in rem_words]\n","    # lemmitise\n","    #[item.upper() for item in mylis]\n","    sent = [lemmatiser.lemmatize(item, pos=\"v\") for item  in sent ]\n","    return(unique(sent))"],"metadata":{"id":"5-XBNnrIj8eA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title chatbot\n","def tellme_bot():\n","    while(1):\n","        response = input(\"Tell Me. [q to quit]>\")\n","        if response == 'q':\n","            break\n","        i=0\n","        chosen = len(pairs)\n","        matches = 0\n","        list_response=preprocessing(response)\n","        while (i<len(pairs)):\n","            loc_matches = 0\n","            x=pairs[i][0] + \"  \".join(pairs[i][1])\n","            list_pair=preprocessing(x)\n","            for word in list_pair:\n","                if word in list_response:\n","                    loc_matches=loc_matches+1\n","            if ( loc_matches > matches ):\n","                chosen = i\n","                matches = loc_matches\n","            i = i + 1\n","        if ( chosen <len(pairs) ) :\n","            ans=pairs[chosen][1]\n","            print(ans[0] )\n","        else :\n","            print(\"Unable to answer this question\" )\n","        break\n","Let us now call our bot with input \"CAN I RESERVE RAILWAYS BOOKING\" and see its response.\n","tellme_bot()\n","#prints Tell Me. [q to quit]>CAN I RESERVE RAILWAYS BOOKING\n","Recently internet reservation facility has started on Indian Railways. The web site http://www.irctc.co.in\n","is operational, wherein you can get the railway reservation done through Credit Cards.For more on Reservation\n","through credit cards click here Internet Reservation\n","tellme_bot()\n","Tell Me. [q to quit]>How do I buy a laptop\n","Unable to answer this question"],"metadata":{"id":"qR1WjJTkkq_v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","topic modeling\n","--\n","---"],"metadata":{"id":"PvZQ_UhoZawi"}},{"cell_type":"code","source":["# a type of statiscal moelling to find the topics and its frequency in a particular focument\n","#LDA(latent Direchlet allocation)\n","\n","from nltk.corpus import stopwords\n","from nltk.stem.wordnet import WordNetLemmatizer\n","import string\n","import gensim\n","from gensim import corpora\n","from nltk.corpus import stopwords\n","from nltk.stem.wordnet import WordNetLemmatizer\n","import string\n","import gensim\n","from gensim import corpora\n","Step 2: Getting data\n","docs1=\"Sugar causes blood glucose to spike and plummet. Unstable blood sugar often leads to mood swings, fatigue, headaches and cravings for more sugar. Cravings set the stage for a cycle of addiction in which every new hit of sugar makes you feel better temporarily but, a few hours later, results in more cravings and hunger. On the flip side, those who avoid sugar often report having little or no cravings for sugary things and feeling emotionally balanced and energized.\"\n","docs2=\"Sugar increases the risk of obesity, diabetes and heart disease. Large-scale studies have shown that the more high-glycemic foods (those that quickly affect blood sugar), including foods containing sugar, a person consumes, the higher his risk for becoming obese and for developing diabetes and heart disease1. Emerging research is also suggesting connections between high-glycemic diets and many different forms of cancer.\"\n","docs3=\"Sugar interferes with immune function. Research on human subjects is scant, but animal studies have shown that sugar suppresses immune response5. More research is needed to understand the exact mechanisms; however, we do know that bacteria and yeast feed on sugar and that, when these organisms get out of balance in the body, infections and illness are more likely.\"\n","docs4=\"A high-sugar diet often results in chromium deficiency. Its sort of a catch-22. If you consume a lot of sugar and other refined carbohydrates, you probably dont get enough of the trace mineral chromium, and one of chromiums main functions is to help regulate blood sugar. Scientists estimate that 90 percent of Americans dont get enough chromium. Chromium is found in a variety of animal foods, seafood and plant foods. Refining starches and other carbohydrates rob these foods of their chromium supplies.\"\n","docs5=\"Sugar accelerates aging. It even contributes to that telltale sign of aging: sagging skin. Some of the sugar you consume, after hitting your bloodstream, ends up attaching itself to proteins, in a process called glycation. These new molecular structures contribute to the loss of elasticity found in aging body tissues, from your skin to your organs and arteries7. The more sugar circulating in your blood, the faster this damage takes hold.\"\n","docs6=\"Sugar causes tooth decay. With all the other life-threatening effects of sugar, we sometimes forget the most basic damage it does. When it sits on your teeth, it creates decay more efficiently than any other food substance8. For a strong visual reminder, next time the Tooth Fairy visits, try the old tooth-in-a-glass-of-Coke experiment—the results will surely convince you that sugar isnt good for your pearly whites.\"\n","docs7=\"Sugar can cause gum disease, which can lead to heart disease. Increasing evidence shows that chronic infections, such as those that result from periodontal problems, play a role in the development of coronary artery disease9. The most popular theory is that the connection is related to widespread effects from the bodys inflammatory response to infection.\"\n","docs7=\"Sugar affects behavior and cognition in children. Though it has been confirmed by millions of parents, most researchers have not been able to show the effect of sugar on childrens behavior. A possible problem with the research is that most of it compared the effects of a sugar-sweetened drink to one containing an artificial sweetener10. It may be that kids react to both real sugar and sugar substitutes, therefore showing no differences in behavior. What about kids ability to learn? Between 1979 and 1983, 803 New York City public schools reduced the amount of sucrose (table sugar) and eliminated artificial colors, flavors and two preservatives from school lunches and breakfasts. The diet policy changes were followed by a 15.7 percent increase in a national academic ranking (previously, the greatest improvement ever seen had been 1.7 percent).\"\n","docs8=\"Sugar increases stress. When were under stress, our stress hormone levels rise; these chemicals are the bodys fight-or-flight emergency crew, sent out to prepare the body for an attack or an escape. These chemicals are also called into action when blood sugar is low. For example, after a blood-sugar spike (say, from eating a piece of birthday cake), theres a compensatory dive, which causes the body to release stress hormones such as adrenaline, epinephrine and cortisol. One of the main things these hormones do is raise blood sugar, providing the body with a quick energy boost. The problem is, these helpful hormones can make us feel anxious, irritable and shaky.\"\n","docs9=\"Sugar takes the place of important nutrients. According to USDA data, people who consume the most sugar have the lowest intakes of essential nutrients––especially vitamin A, vitamin C, folate, vitamin B-12, calcium, phosphorous, magnesium and iron. Ironically, those who consume the most sugar are children and teenagers, the individuals who need these nutrients most12.\"\n","docs10=\"Slashing Sugar. Now that you know the negative impacts refined sugar can have on your body and mind, youll want to be more careful about the foods you choose. And the first step is getting educated about where sugar lurks—believe it or not, a food neednt even taste all that sweet for it to be loaded with sugar. When it comes to convenience and packaged foods, let the ingredients label be your guide, and be aware that just because something boasts that it is low in carbs or a diet food, doesnt mean its free of sugar. Atkins products never contain added sugar.\"\n","# compile documents\n","doc_complete=[docs1,docs2,docs3, docs4,docs5,docs6,docs7,docs8,docs9,docs10]\n","stop_set = set(stopwords.words('english'))\n","exclude_set = set(string.punctuation)\n","lemmatize = WordNetLemmatizer()\n","def clean_doc(doc):\n","    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop_set])\n","    punc_free = ''.join(i for i in stop_free if i not in exclude_set)\n","    normalized = \" \".join(lemmatize.lemmatize(w) for w in punc_free.split())\n","    return normalized\n","cleaned = [clean_doc(doc).split() for doc in doc_complete]\n","# Every unique term is assigned an index in our term document matrix.\n","dictionary = corpora.Dictionary(cleaned)\n","# Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n","doc_term_matrix = [dictionary.doc2bow(doc) for doc in cleaned]\n","# Creating an LDA object\n","Lda = gensim.models.ldamodel.LdaModel\n","# Running and Training LDA model on the document term matrix.\n","ldamodel = Lda(doc_term_matrix, num_topics=5, id2word = dictionary, passes=300)\n","#Result\n","topics = ldamodel.print_topics(num_topics=5, num_words=5)\n","for  i in topics :\n","    print (i)\n"],"metadata":{"id":"RQXVcKeJlXcP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["stock prediction\n","--\n","---"],"metadata":{"id":"YwP6EcaCaLCM"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import keras\n","from keras.models import Sequential\n","from keras.layers.recurrent import SimpleRNN\n","from keras.layers.core import Dense, Activation, Dropout\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import mean_squared_error\n","from sklearn.utils import shuffle\n","# Loading data\n","data = pd.read_csv('INFY20002008.csv')\n","data.info()"],"metadata":{"id":"DzeA6x-NaRiG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title preprocessing\n","# Selecting only Date and Average Price columns\n","data = data[['Date', 'Average Price']]\n","# Scaling the values in the range of 0 to 1\n","scaler = MinMaxScaler(feature_range = (0, 1))\n","scaled_price = scaler.fit_transform(data.loc[:, 'Average Price'].values.reshape(-1, 1))# Splitting dataset in the ratio of 75:25 for training and test\n","train_size = int(data.shape[0] * 0.75)\n","train, test = scaled_price[0:train_size, :], scaled_price[train_size:data.shape[0], :]\n","print(\"Number of entries (training set, test set): \" + str((len(train), len(test))))\n","\n"],"metadata":{"id":"MZ3Yqrc-aZ5N","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_dataset(scaled_price, window_size=1):\n","    data_X, data_Y = [], []\n","    for i in range(len(scaled_price) - window_size - 1):\n","        a = scaled_price[i:(i + window_size), 0]\n","        data_X.append(a)\n","        data_Y.append(scaled_price[i + window_size, 0])\n","    return(np.array(data_X), np.array(data_Y))\n","# Create test and training sets for one-step-ahead regression.\n","window_size = 3\n","train_X, train_Y = create_dataset(train, window_size)\n","test_X, test_Y = create_dataset(test, window_size)\n","print(\"Original training data shape:\")\n","print(train_X.shape)\n","# Reshape the input data into appropriate form for Keras.\n","train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n","test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n","print(\"New training data shape:\")\n","print(train_X.shape)"],"metadata":{"id":"CxIVg28sa_Yo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title model\n","# Designing the SimpleRNN model\n","model = Sequential()\n","model.add(SimpleRNN(4, input_shape = (1, window_size)))\n","model.add(Dense(1))\n","# Compiling the model\n","model.compile(loss = \"mean_squared_error\", optimizer = \"adam\")\n","# Training the model\n","model.fit(train_X, train_Y, epochs=3, batch_size=1)"],"metadata":{"id":"3XqUr-2ebWtZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title predictions and visualization\n","# Make predictions on the original scale of the data.\n","    pred = scaler.inverse_transform(model.predict(X))\n","    # Prepare Y data to also be on the original scale for interpretability.\n","    orig_data = scaler.inverse_transform([Y])\n","    # Calculate RMSE.\n","    score = np.sqrt(mean_squared_error(orig_data[0], pred[:, 0]))\n","    return(score, pred)\n","rmse_train, train_predict = predict_and_score(model, train_X, train_Y)\n","rmse_test, test_predict = predict_and_score(model, test_X, test_Y)\n","print(\"Training data score: %.2f RMSE\" % rmse_train)\n","print(\"Test data score: %.2f RMSE\" % rmse_test)\n","\n","# Start with training predictions.\n","train_predict_plot = np.empty_like(scaled_price)\n","train_predict_plot[:, :] = np.nan\n","train_predict_plot[window_size:len(train_predict) + window_size, :] = train_predict\n","# Add test predictions.\n","test_predict_plot = np.empty_like(scaled_price)\n","test_predict_plot[:, :] = np.nan\n","test_predict_plot[len(train_predict) + (window_size * 2) + 1:len(scaled_price) - 1, :] = test_predict\n","# Create the plot.\n","plt.figure(figsize = (15, 5))\n","plt.plot(scaler.inverse_transform(scaled_price), label = \"True value\")\n","plt.plot(train_predict_plot, label = \"Training set prediction\")\n","plt.plot(test_predict_plot, label = \"Test set prediction\")\n","plt.xlabel(\"Days\")\n","plt.ylabel(\"Average Price\")\n","plt.title(\"Comparison true vs. predicted training / test\")\n","plt.legend()\n","plt.show()"],"metadata":{"id":"qFp2mqUKcXa3","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["predict a sequence of text\n","--\n","---"],"metadata":{"id":"sYdzrO4GdHAN"}},{"cell_type":"code","source":["# source text\n","data = \"\"\"Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data.\\n\n","             Challenges in natural language processing frequently involve speech recognition, natural language understanding, and natural-language generation.\\n\n","             Natural language processing has its roots in the 1950s.\\n\n","             Already in 1950, Alan Turing published an article titled Computing Machinery and Intelligence which proposed what is now called the Turing test as a criterion of intelligence, a task that involves the automated interpretation and generation of natural language, but at the time not articulated as a problem separate from artificial intelligence.\\n\n","             The following is a list of some of the most commonly researched tasks in natural language processing.\\n\n","             Some of these tasks have direct real-world applications, while others more commonly serve as subtasks that are used to aid in solving larger tasks.\\n\n","             Though natural language processing tasks are closely intertwined, they can be subdivided into categories for convenience.\\n\"\"\"\n","\n","import nltk\n","\n","\n","# Preparing the dataset\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","all_sentences = nltk.sent_tokenize(data)\n","all_words = [nltk.word_tokenize(sent) for sent in all_sentences]\n","\n","# Removing Stop Words\n","from nltk.corpus import stopwords\n","for i in range(len(all_words)):\n","    all_words[i] = [w for w in all_words[i] if w not in stopwords.words('english')]\n","\n","\n","!pip install gensim\n","from gensim.models import Word2Vec\n","word2vec = Word2Vec(all_words, min_count=1)\n","word2vec.most_similar('natural')\n","word2vec.most_similar('language')\n","from keras.preprocessing.text import Tokenizer\n","from keras.utils import to_categorical\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import LSTM\n","from keras.layers import Embedding\n","\n","# integer encode text\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts([data])\n","encoded = tokenizer.texts_to_sequences([data])[0]\n","\n","# determine the vocabulary size\n","vocab_size = len(tokenizer.word_index) + 1\n","print('Vocabulary Size: %d' % vocab_size)\n","\n","#Vocabulary Size: 108\n","import numpy as np\n","\n","\n","# create word -> word sequences\n","sequences = list()\n","for i in range(1, len(encoded)):\n","\tsequence = encoded[i-1:i+1]\n","\tsequences.append(sequence)\n","print('Total Sequences: %d' % len(sequences))\n","\n","# split into X and y elements\n","sequences = np.array(sequences)\n","X, y = sequences[:,0],sequences[:,1]\n","#Total Sequences: 173\n","\n","# one hot encode outputs\n","y = to_categorical(y, num_classes=vocab_size)\n","\n","\n","# define model\n","model = Sequential()\n","model.add(Embedding(vocab_size, 10, input_length=1))\n","model.add(LSTM(50))\n","model.add(Dense(vocab_size, activation='softmax'))\n","print(model.summary())\n","\n","# compile network\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# fit network\n","model.fit(X, y, epochs=200, verbose=2)\n","\n","# generate a sequence from the model\n","def generate_seq(model, tokenizer, seed_text, n_words):\n","\tin_text, result = seed_text, seed_text\n","\t# generate a fixed number of words\n","\tfor _ in range(n_words):\n","\t\t# encode the text as integer\n","\t\tencoded = tokenizer.texts_to_sequences([in_text])[0]\n","\t\tencoded = np.array(encoded)\n","\t\t# predict a word in the vocabulary\n","\t\tyhat = model.predict_classes(encoded, verbose=0)\n","\t\t# map predicted word index to word\n","\t\tout_word = ''\n","\t\tfor word, index in tokenizer.word_index.items():\n","\t\t\tif index == yhat:\n","\t\t\t\tout_word = word\n","\t\t\t\tbreak\n","\t\t# append to input\n","\t\tin_text, result = out_word, result + ' ' + out_word\n","\treturn result\n","print(generate_seq(model, tokenizer, 'language', 4))\n","#Output :  language processing tasks are closel"],"metadata":{"id":"l-IbVqhoQus-"},"execution_count":null,"outputs":[]}]}